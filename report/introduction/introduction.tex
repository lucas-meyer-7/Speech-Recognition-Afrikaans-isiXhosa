\graphicspath{{introduction/fig/}}

\chapter{Introduction} \label{chap:introduction}
%
%
%  USE HERMAN KAMPER INTRODUCTION SECTION AS REF 
%
%
The development and application of automatic speech recognition (ASR) models have been steadily growing, 
offering solutions across a myriad of domains from transcription services to voice command recognition. 
However, a significant gap remains when it comes to lesser-resourced languages, with Afrikaans and isiXhosa 
being pertinent examples. These languages, despite their rich linguistic tapestry and cultural significance, 
have been somewhat overlooked in the sphere of ASR development.

The advent of pre-trained models, specifically the wav2vec 2.0 model, has provided a promising avenue to bridge this gap. 
Pre-trained models, with their ability to leverage vast amounts of data and capture intricate patterns, 
can be fine-tuned to cater to specific languages, potentially offering high-quality ASR solutions even for lesser-resourced languages. 
However, the methodology behind this fine-tuning process is crucial. It determines the efficacy of the resultant model and its applicability to real-world scenarios.

This study aims to explore the effectiveness of a sequential fine-tuning strategy in building ASR models 
for Afrikaans and isiXhosa using pre-trained wav2vec 2.0 models. The core research question driving this investigation is: 
"Does our proposed sequential fine-tuning strategy perform better than a simple fine-tuning strategy?" 
By juxtaposing these strategies, the study seeks to unearth the nuances of the fine-tuning process, 
offering insights into optimizing ASR models for languages that have hitherto remained underrepresented in this domain.

The sequential fine-tuning strategy involves a multi-step process, adjusting the model progressively to better 
align with the unique phonetic and linguistic characteristics of Afrikaans and isiXhosa. 
In contrast, the simple fine-tuning strategy offers a more direct approach. By comparing these strategies head-to-head, 
the study aims to provide a clear direction for future ASR development endeavors for lesser-resourced languages.

\textit{At this point, the introduction would transition to discussing results and conclusions, which are yet to be determined.}