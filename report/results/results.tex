\graphicspath{{results/fig/}}

\chapter{Results} \label{chap:results}
In this chapter, we discuss our experimental results. 
We first discuss the results for our basic fine-tuning experiments, 
and then we discuss the results for our sequential fine-tuning experiments.
We do not include the results of all our experiments, only the experiments that resulted in the best WER (\ref{subsec:wer}).
The results for all of our experiments are provided in Appendix A.

\section{Basic fine-tuning results}
For the basic fine-tuning experiments, each model is fine-tuned on one language. 
Since this study is focused on performing ASR for Afrikaans and isiXhosa, 
we only use Afrikaans and isiXhosa speech data for our basic fine-tuning experiments.

\subsection{Afrikaans results}
Table \ref{tbl:basic-af} provides the results of the best Afrikaans model using the basic fine-tuning strategy,
with and without the use of a $5$-gram LM (Kneser-Ney smoothing). For more information about the hyperparameters and training history of this model,
refer to the \href{https://huggingface.co/lucas-meyer/xls-r-asr_af-run2}{model repository}.
Table \ref{tbl:full-basic-af} in Appendix \ref{appen:results} provides the results of all our basic fine-tuning experiments for Afrikaans ASR.

\begin{table}[!h]
    \renewcommand{\arraystretch}{1.1}
    \centering
    \caption{The WER of the best Afrikaans model using the basic fine-tuning strategy. 
    The model is evaluated on the validation and test data of the Afrikaans dataset (\href{https://huggingface.co/datasets/lucas-meyer/asr_af}{\texttt{asr\_af}}).}
    \begin{tabularx}{0.65\linewidth}{@{}lCCr@{}}
        \toprule
        & \multicolumn{2}{c}{WER} \\
        \cmidrule(lr){2-3}
        Model                                          & Validation & Test   \\
        \midrule
        Fine-tune on \verb|asr_af|                     & $0.3798$     & $0.3801$ \\
        Fine-tune on \verb|asr_af| (with LM)           & $0.2908$     & $0.2874$ \\
        \bottomrule
    \end{tabularx}
    \label{tbl:basic-af}
\end{table}

\newpage

\subsection{isiXhosa results}
Table \ref{tbl:basic-xh} provides the results of the best isiXhosa model using the basic fine-tuning strategy,
with and without the use of a $5$-gram LM (Kneser-Ney smoothing). For more information about the hyperparameters and training history of this model,
refer to the \href{https://huggingface.co/lucas-meyer/xls-r-asr_xh-run1}{model repository}.
Table \ref{tbl:full-basic-xh} in Appendix \ref{appen:results} provides the results of all our basic fine-tuning experiments for isiXhosa ASR.

\begin{table}[!h]
    \renewcommand{\arraystretch}{1.1}
    \centering
    \caption{The WER of the best isiXhosa model using the basic fine-tuning strategy. 
    The model is evaluated on the validation and test data of the isiXhosa dataset (\href{https://huggingface.co/datasets/lucas-meyer/asr_xh}{\texttt{asr\_xh}}).}
    \begin{tabularx}{0.65\linewidth}{@{}lCCr@{}}
        \toprule
        & \multicolumn{2}{c}{WER} \\
        \cmidrule(lr){2-3}
        Model                                          & Validation & Test   \\
        \midrule
        Fine-tune on \verb|asr_xh|                     & $0.5008$     & $0.5052$ \\
        Fine-tune on \verb|asr_xh| (with LM)           & $0.4014$     & $0.4147$ \\
        \bottomrule
    \end{tabularx}
    \label{tbl:basic-xh}
\end{table}



\section{Sequential fine-tuning results}
For the basic fine-tuning experiments, each model is fine-tuned on two language in two seperate runs. 
We use the \href{https://huggingface.co/datasets/google/fleurs}{FLEURS} dataset to perform basic fine-tuning experiments on Dutch (\verb|FLEURS_nl|) and isiZulu (\verb|FLEURS_zu|).
Then, we use the best Dutch and isiZulu models for further fine-tuning on Afrikaans and isiXhosa respectively.

\subsection{Afrikaans results}
Table \ref{tbl:seq-af} provides the results of the best Afrikaans model using the sequential fine-tuning strategy,
with and without the use of a $5$-gram LM (Kneser-Ney smoothing). 
For more information about the hyperparameters and training history of this model, 
refer to the \href{}{model repository}.
Table \ref{tbl:full-seq-af} in Appendix \ref{appen:results} provides the results of all our sequential fine-tuning experiments for Afrikaans ASR.

\begin{table}[!h]
    \renewcommand{\arraystretch}{1.1}
    \centering
    \caption{The WER of the best Afrikaans model using the sequential fine-tuning strategy. 
    The model is evaluated on the validation and test data of the Afrikaans dataset (\href{https://huggingface.co/datasets/lucas-meyer/asr_af}{\texttt{asr\_af}}).}
    \begin{tabularx}{0.65\linewidth}{@{}lCCr@{}}
        \toprule
        & \multicolumn{2}{c}{WER} \\
        \cmidrule(lr){2-3}
        Model                                             & Validation   & Test   \\
        \midrule
        Fine-tune on \verb|FLEURS_nl|                     & $0.3671$     & $0.3716$ \\
        and \verb|asr_af| \\
        Fine-tune on \verb|FLEURS_nl|                     & $0.2743$     & $0.2796$ \\
        and \verb|asr_af| (with LM) \\
        \bottomrule
    \end{tabularx}
    \label{tbl:seq-af}
\end{table}

\subsection{isiXhosa results}
Table \ref{tbl:seq-xh} provides the results of the best isiXhosa model using the sequential fine-tuning strategy,
with and without the use of a $5$-gram LM (Kneser-Ney smoothing). 
For more information about the hyperparameters and training history of this model, 
refer to the \href{}{model repository}.
Table \ref{tbl:full-seq-xh} in Appendix \ref{appen:results} provides the results of all our sequential fine-tuning experiments for isiXhosa ASR.
    
\begin{table}[!h]
    \renewcommand{\arraystretch}{1.1}
    \centering
    \caption{The WER of the best isiXhosa model using the sequential fine-tuning strategy. 
    The model is evaluated on the validation and test data of the isiXhosa dataset (\href{https://huggingface.co/datasets/lucas-meyer/asr_xh}{\texttt{asr\_xh}}).}
    \begin{tabularx}{0.65\linewidth}{@{}lCCr@{}}
        \toprule
        & \multicolumn{2}{c}{WER} \\
        \cmidrule(lr){2-3}
        Model                                             & Validation   & Test   \\
        \midrule
        Fine-tune on \verb|FLEURS_zu|                     & $0.4945$     & $0.4989$ \\
        and \verb|asr_xh| \\
        Fine-tune on \verb|FLEURS_zu|                     & $0.3923$     & $0.3993$ \\
        and \verb|asr_xh| (with LM) \\
        \bottomrule
    \end{tabularx}
    \label{tbl:seq-xh}
\end{table}



\section{Discussion of results}
For our best Afrikaans models, with and without an LM (Table \ref{tbl:basic-af} and \ref{tbl:seq-af}), the sequential fine-strategy performed slightly better on the validation and test WER.
For our best isiXhosa models, with and without an LM (Table \ref{tbl:basic-xh} and \ref{tbl:seq-xh}), the sequential fine-strategy performed slightly better on the validation and test WER.
The results of several other models (n Appendix \ref{appen:results}) that used the sequential fine-tuning strategy are better than the best basic fine-tuning results.
The advantage of the basic fine-tuning strategy is that it is computationally less expensive compared to the sequential fine-tuning strategy which involves two seperate runs.