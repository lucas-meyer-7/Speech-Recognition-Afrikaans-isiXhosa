{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg_HXRyHC-D6",
        "outputId": "4e1f397c-12e7-47ef-b573-53585aec7731"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Looking in indexes: https://pypi.org/simple, https://packagecloud.io/github/git-lfs/pypi/simple\n",
            "Requirement already satisfied: datasets in /home/kiff/.local/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.14.4)\n",
            "Requirement already satisfied: evaluate in /home/kiff/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.4.0)\n",
            "Requirement already satisfied: huggingface_hub in /home/kiff/.local/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.16.4)\n",
            "Requirement already satisfied: librosa in /home/kiff/.local/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.10.0.post2)\n",
            "Requirement already satisfied: numpy in /home/kiff/.local/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.23.5)\n",
            "Requirement already satisfied: pandas in /home/kiff/.local/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.5.3)\n",
            "Requirement already satisfied: Requests in /home/kiff/.local/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (2.31.0)\n",
            "Requirement already satisfied: torch in /home/kiff/.local/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (2.0.1)\n",
            "Requirement already satisfied: tqdm in /home/kiff/.local/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (4.65.0)\n",
            "Requirement already satisfied: transformers in /home/kiff/.local/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (4.28.0)\n",
            "Requirement already satisfied: scipy in /usr/lib/python3/dist-packages (from -r requirements.txt (line 11)) (1.8.0)\n",
            "Requirement already satisfied: accelerate in /home/kiff/.local/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.20.1)\n",
            "Requirement already satisfied: werkzeug in /home/kiff/.local/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (2.2.2)\n",
            "Requirement already satisfied: jiwer in /home/kiff/.local/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (3.0.2)\n",
            "Requirement already satisfied: urllib3==1.26.7 in /home/kiff/.local/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (1.26.7)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /home/kiff/.local/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (12.0.1)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/kiff/.local/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /home/kiff/.local/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /home/kiff/.local/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/kiff/.local/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /home/kiff/.local/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (3.8.5)\n",
            "Requirement already satisfied: packaging in /home/kiff/.local/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from datasets->-r requirements.txt (line 1)) (5.4.1)\n",
            "Requirement already satisfied: responses<0.19 in /home/kiff/.local/lib/python3.10/site-packages (from evaluate->-r requirements.txt (line 2)) (0.18.0)\n",
            "Requirement already satisfied: filelock in /home/kiff/.local/lib/python3.10/site-packages (from huggingface_hub->-r requirements.txt (line 3)) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kiff/.local/lib/python3.10/site-packages (from huggingface_hub->-r requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /home/kiff/.local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /home/kiff/.local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /home/kiff/.local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 4)) (1.2.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /home/kiff/.local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 4)) (5.1.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /home/kiff/.local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 4)) (0.57.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /home/kiff/.local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /home/kiff/.local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 4)) (1.6.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /home/kiff/.local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 4)) (0.3.5)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /home/kiff/.local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 4)) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /home/kiff/.local/lib/python3.10/site-packages (from librosa->-r requirements.txt (line 4)) (1.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /home/kiff/.local/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->-r requirements.txt (line 6)) (2022.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kiff/.local/lib/python3.10/site-packages (from Requests->-r requirements.txt (line 7)) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from Requests->-r requirements.txt (line 7)) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/kiff/.local/lib/python3.10/site-packages (from Requests->-r requirements.txt (line 7)) (2023.7.22)\n",
            "Requirement already satisfied: sympy in /usr/lib/python3/dist-packages (from torch->-r requirements.txt (line 8)) (1.9)\n",
            "Requirement already satisfied: networkx in /home/kiff/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /home/kiff/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (3.0.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/kiff/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/kiff/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/kiff/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/kiff/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/kiff/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/kiff/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/kiff/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/kiff/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/kiff/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/kiff/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/kiff/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /home/kiff/.local/lib/python3.10/site-packages (from torch->-r requirements.txt (line 8)) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /home/kiff/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 8)) (68.0.0)\n",
            "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->-r requirements.txt (line 8)) (0.37.1)\n",
            "Requirement already satisfied: cmake in /home/kiff/.local/lib/python3.10/site-packages (from triton==2.0.0->torch->-r requirements.txt (line 8)) (3.26.3)\n",
            "Requirement already satisfied: lit in /home/kiff/.local/lib/python3.10/site-packages (from triton==2.0.0->torch->-r requirements.txt (line 8)) (16.0.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/kiff/.local/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 10)) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/kiff/.local/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 10)) (0.13.3)\n",
            "Requirement already satisfied: psutil in /home/kiff/.local/lib/python3.10/site-packages (from accelerate->-r requirements.txt (line 12)) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/kiff/.local/lib/python3.10/site-packages (from werkzeug->-r requirements.txt (line 13)) (2.1.3)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /home/kiff/.local/lib/python3.10/site-packages (from jiwer->-r requirements.txt (line 14)) (8.1.6)\n",
            "Requirement already satisfied: rapidfuzz==2.13.7 in /home/kiff/.local/lib/python3.10/site-packages (from jiwer->-r requirements.txt (line 14)) (2.13.7)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (21.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/kiff/.local/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/kiff/.local/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/kiff/.local/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/kiff/.local/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/kiff/.local/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /home/kiff/.local/lib/python3.10/site-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 4)) (0.40.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/lib/python3/dist-packages (from pooch<1.7,>=1.0->librosa->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/kiff/.local/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /home/kiff/.local/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 4)) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /home/kiff/.local/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 4)) (2.21)\n",
            "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip3 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H6mdaEcoyvkN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-09-14 21:46:20.242168: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-09-14 21:46:21.304899: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict, List, Union\n",
        "\n",
        "from utils import SR, WRITE_ACCESS_TOKEN, clear_cache, change_pwd\n",
        "change_pwd()\n",
        "\n",
        "from accelerate import Accelerator\n",
        "from accelerate.logging import get_logger\n",
        "from datasets import Audio, Dataset, load_dataset\n",
        "from transformers import (\n",
        "    Wav2Vec2Config,\n",
        "    Wav2Vec2Model,\n",
        "    Wav2Vec2FeatureExtractor,\n",
        "    Wav2Vec2CTCTokenizer,\n",
        "    Wav2Vec2Processor,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eyDT8Gj0z9FG"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import math\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Union\n",
        "from tqdm import tqdm\n",
        "\n",
        "import datasets\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from datasets import DatasetDict, concatenate_datasets, load_dataset, IterableDatasetDict\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import transformers\n",
        "from accelerate import Accelerator\n",
        "from accelerate.logging import get_logger\n",
        "from huggingface_hub import Repository\n",
        "from transformers import (\n",
        "    SchedulerType,\n",
        "    Wav2Vec2Config,\n",
        "    Wav2Vec2FeatureExtractor,\n",
        "    Wav2Vec2ForPreTraining,\n",
        "    get_scheduler,\n",
        "    set_seed,\n",
        ")\n",
        "from transformers.models.wav2vec2.modeling_wav2vec2 import _compute_mask_indices, _sample_negative_indices\n",
        "from transformers.utils import get_full_repo_name\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TgigjKfSyvkX"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, files, sep, sr, audio_column_name, duration_column_name, min_duration, max_duration, dataset_name):\n",
        "        self.sep = sep\n",
        "        self.sr = sr\n",
        "        self.min_duration = min_duration\n",
        "        self.max_duration = max_duration\n",
        "        self.audio_column_name = audio_column_name\n",
        "        self.duration_column_name = duration_column_name\n",
        "        self.dataset_name = dataset_name\n",
        "        self.data = self.load_ds(files)\n",
        "\n",
        "    def load_ds(self, all_files):\n",
        "        li = []\n",
        "        for filename in all_files:\n",
        "            df = pd.read_csv(filename, sep=self.sep, engine=\"python\")\n",
        "            li.append(df)\n",
        "        data = pd.concat(li, axis=0, ignore_index=True)\n",
        "\n",
        "        if self.duration_column_name in data.columns:\n",
        "            data = data[data[self.duration_column_name] >= self.min_duration]\n",
        "            print(\"Mean duration: \", data[self.duration_column_name].mean())\n",
        "        return data\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data.iloc[idx]\n",
        "        batch = {}\n",
        "        batch[\"input_values\"] = sf.read(os.path.join(self.dataset_name, item[\"path\"]))[0]\n",
        "\n",
        "        if len(batch[\"input_values\"])//self.sr > self.max_duration:\n",
        "            start = np.random.randint(0, len(batch[\"input_values\"]) - self.max_duration * self.sr)\n",
        "            batch[\"input_values\"] = batch[\"input_values\"][start : start + int(self.max_duration * self.sr)]\n",
        "\n",
        "        return batch\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorForWav2Vec2Pretraining:\n",
        "    \"\"\"\n",
        "    Data collator that will dynamically pad the inputs received and prepare masked indices\n",
        "    for self-supervised pretraining.\n",
        "\n",
        "    Args:\n",
        "        model (:class:`~transformers.Wav2Vec2ForPreTraining`):\n",
        "            The Wav2Vec2 model used for pretraining. The data collator needs to have access\n",
        "            to config and ``_get_feat_extract_output_lengths`` function for correct padding.\n",
        "        feature_extractor (:class:`~transformers.Wav2Vec2FeatureExtractor`):\n",
        "            The processor used for proccessing the data.\n",
        "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
        "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
        "            among:\n",
        "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
        "              sequence if provided).\n",
        "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
        "              maximum acceptable input length for the model if that argument is not provided.\n",
        "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
        "              different lengths).\n",
        "        max_length (:obj:`int`, `optional`):\n",
        "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
        "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
        "            If set will pad the sequence to a multiple of the provided value.\n",
        "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
        "            7.5 (Volta).\n",
        "    \"\"\"\n",
        "\n",
        "    model: Wav2Vec2ForPreTraining\n",
        "    feature_extractor: Wav2Vec2FeatureExtractor\n",
        "    padding: Union[bool, str] = \"longest\"\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # reformat list to dict and set to pytorch format\n",
        "        batch = self.feature_extractor.pad(\n",
        "            features,\n",
        "            padding=self.padding,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        device = batch[\"input_values\"].device\n",
        "        batch_size = batch[\"input_values\"].shape[0]\n",
        "\n",
        "        mask_indices_seq_length = self.model._get_feat_extract_output_lengths(batch[\"input_values\"].shape[-1])\n",
        "        # make sure masked sequence length is a Python scalar\n",
        "        mask_indices_seq_length = int(mask_indices_seq_length)\n",
        "\n",
        "        # make sure that no loss is computed on padded inputs\n",
        "        if batch.get(\"attention_mask\") is not None:\n",
        "            # compute real output lengths according to convolution formula\n",
        "            batch[\"sub_attention_mask\"] = self.model._get_feature_vector_attention_mask(\n",
        "                mask_indices_seq_length, batch[\"attention_mask\"]\n",
        "            )\n",
        "\n",
        "        features_shape = (batch_size, mask_indices_seq_length)\n",
        "\n",
        "        # sample randomly masked indices\n",
        "        mask_time_indices = _compute_mask_indices(\n",
        "            features_shape,\n",
        "            self.model.config.mask_time_prob,\n",
        "            self.model.config.mask_time_length,\n",
        "            attention_mask=batch.get(\"sub_attention_mask\")\n",
        "        )\n",
        "        # sample negative indices\n",
        "        sampled_negative_indices = _sample_negative_indices(\n",
        "            features_shape,\n",
        "            self.model.config.num_negatives,\n",
        "            mask_time_indices=mask_time_indices,\n",
        "        )\n",
        "        batch[\"mask_time_indices\"] = torch.tensor(mask_time_indices, dtype=torch.long, device=device)\n",
        "        batch[\"sampled_negative_indices\"] = torch.tensor(sampled_negative_indices, dtype=torch.long, device=device)\n",
        "\n",
        "        return batch\n",
        "\n",
        "\n",
        "def multiply_grads(params, c):\n",
        "    \"\"\"Multiplies grads by a constant *c*.\"\"\"\n",
        "    for p in params:\n",
        "        if p.grad is not None:\n",
        "            if torch.is_tensor(c):\n",
        "                c = c.to(p.grad.device)\n",
        "            p.grad.data.mul_(c)\n",
        "\n",
        "\n",
        "def get_grad_norm(params, scale=1):\n",
        "    \"\"\"Compute grad norm given a gradient scale.\"\"\"\n",
        "    total_norm = 0.0\n",
        "    for p in params:\n",
        "        if p.grad is not None:\n",
        "            param_norm = (p.grad.detach().data / scale).norm(2)\n",
        "            total_norm += param_norm.item() ** 2\n",
        "    total_norm = total_norm**0.5\n",
        "    return total_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "O1Sd1o7VDTfm",
        "outputId": "3faef409-a698-4a9a-8de2-b6d4ad3e22fd"
      },
      "outputs": [],
      "source": [
        "# from load_nchlt_2 import load_nchlt_2\n",
        "\n",
        "# load_nchlt_2(dataset_name=\"nchlt_afr\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vXEEB88x0Cau",
        "outputId": "963f04fe-8015-45a5-eca1-710678e44f05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean duration:  4.224940232477446\n",
            "Mean duration:  4.268920869720192\n",
            "Number of training data:  60522\n",
            "total_batch_size:  128\n",
            "num_update_steps_per_epoch:  473\n",
            "num_train_epochs:  423\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kiff/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3eeabfe6ed614d29a95ced83b2519f72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/200000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "******STARTING AT EPOCH 0 - STEP 0******\n",
            "\n",
            "Epoch 0: \n",
            "| step: 1.000e+00| loss: 4.669e+00| contrast_loss: 4.602e+00| div_loss: 6.743e-01| %_mask_idx: 8.087e-02| ppl: 2.085e+02| lr: 1.562e-07| temp: 2.000e+00| grad_norm: nan| cosine_sim: -3.904e+00\n"
          ]
        }
      ],
      "source": [
        "logger = get_logger(__name__)\n",
        "\n",
        "output_dir = \"wav2vec2-pretraining-output\"\n",
        "push_to_hub = False\n",
        "hub_model_id = \"wav2vec2-pretrained-model\"\n",
        "resume = False\n",
        "\n",
        "train_datasets = [os.path.join(\"nchlt_afr\", \"train.csv\")]\n",
        "val_datasets = [os.path.join(\"nchlt_afr\", \"validation.csv\")]\n",
        "separator = \",\"\n",
        "audio_column_name = \"path\"\n",
        "duration_column_name = \"duration\"\n",
        "min_duration_in_seconds = 0.5\n",
        "max_duration_in_seconds = 25.0\n",
        "\n",
        "per_device_train_batch_size = 16\n",
        "per_device_eval_batch_size = 8\n",
        "gradient_accumulation_steps = 8\n",
        "learning_rate = 0.005\n",
        "lr_scheduler_type = \"linear\"\n",
        "adam_beta1 = 0.9\n",
        "adam_beta2 = 0.999\n",
        "adam_epsilon = 1e-8\n",
        "weight_decay = 0.01\n",
        "\n",
        "max_gumbel_temperature = 2.0\n",
        "min_gumbel_temperature = 0.5\n",
        "gumbel_temperature_decay = 0.999995\n",
        "\n",
        "num_train_epochs = 30\n",
        "num_warmup_steps = 32000\n",
        "max_train_steps = 200000\n",
        "saving_steps = 100\n",
        "logging_steps = 1\n",
        "\n",
        "# Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n",
        "accelerator = Accelerator(dispatch_batches=False)\n",
        "logger.info(accelerator.state, main_process_only=False)\n",
        "if accelerator.is_local_main_process:\n",
        "    # set up tensorboard if available\n",
        "    writer = SummaryWriter(output_dir + '/logs', max_queue=5, flush_secs=30)\n",
        "\n",
        "# Set the training seed now.\n",
        "set_seed(42)\n",
        "\n",
        "# Handle the repository creation\n",
        "if accelerator.is_main_process:\n",
        "    if push_to_hub:\n",
        "        if hub_model_id is None:\n",
        "            repo_name = get_full_repo_name(Path(output_dir).name, token=WRITE_ACCESS_TOKEN)\n",
        "        else:\n",
        "            repo_name = hub_model_id\n",
        "        repo = Repository(output_dir, clone_from=repo_name)\n",
        "    elif output_dir is not None:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "accelerator.wait_for_everyone()\n",
        "\n",
        "# Download data\n",
        "train_dataset = CustomDataset(\n",
        "    files=train_datasets,\n",
        "    sep=separator,\n",
        "    audio_column_name=audio_column_name,\n",
        "    duration_column_name=duration_column_name,\n",
        "    sr=SR,\n",
        "    min_duration=min_duration_in_seconds,\n",
        "    max_duration=max_duration_in_seconds,\n",
        "    dataset_name=\"nchlt_afr\",\n",
        ")\n",
        "\n",
        "val_dataset = CustomDataset(\n",
        "    files=val_datasets,\n",
        "    sep=separator,\n",
        "    audio_column_name=audio_column_name,\n",
        "    duration_column_name=duration_column_name,\n",
        "    sr=SR,\n",
        "    min_duration=min_duration_in_seconds,\n",
        "    max_duration=max_duration_in_seconds,\n",
        "    dataset_name=\"nchlt_afr\",\n",
        ")\n",
        "\n",
        "# Load feature_extractor\n",
        "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n",
        "# only normalized-inputs-training is supported\n",
        "if not feature_extractor.do_normalize:\n",
        "    raise ValueError(\n",
        "        \"Training is only supported for normalized inputs. Make sure ``feature_extractor.do_normalize == True``\"\n",
        "    )\n",
        "\n",
        "# Load model config\n",
        "config = Wav2Vec2Config()\n",
        "# if not config.do_stable_layer_norm or config.feat_extract_norm != \"layer\":\n",
        "#     raise ValueError(\n",
        "#         \"PreTraining is only supported for ``config.do_stable_layer_norm=True`` and\"\n",
        "#         \" ``config.feat_extract_norm='layer'\"\n",
        "#     )\n",
        "\n",
        "\n",
        "# initialize random model\n",
        "model = Wav2Vec2ForPreTraining(config)\n",
        "# if load_from_pretrained is not None:\n",
        "#     try:\n",
        "#         model = model.from_pretrained(model_name_or_path)\n",
        "#     except:\n",
        "#         print(\"!!!!! Warning: Pretrained model may not exist. Start training from Scratch\")\n",
        "\n",
        "# Activate gradient checkpointing\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "# Define data collator, optimizer and scheduler\n",
        "data_collator = DataCollatorForWav2Vec2Pretraining(\n",
        "    model=model, feature_extractor=feature_extractor, pad_to_multiple_of=None\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=per_device_train_batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=16,\n",
        "    pin_memory=True,\n",
        "    prefetch_factor=16\n",
        ")\n",
        "\n",
        "eval_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    collate_fn=data_collator,\n",
        "    batch_size=per_device_eval_batch_size,\n",
        "    num_workers=16\n",
        ")\n",
        "\n",
        "# Optimizer\n",
        "optimizer =  torch.optim.AdamW(\n",
        "    list(model.parameters()),\n",
        "    lr=learning_rate,\n",
        "    betas=[adam_beta1, adam_beta2],\n",
        "    eps=adam_epsilon,\n",
        ")\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=lr_scheduler_type,\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=max_train_steps,\n",
        ")\n",
        "\n",
        "# Prepare everything with our `accelerator`.\n",
        "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
        "    model, optimizer, train_dataloader, eval_dataloader\n",
        ")\n",
        "if resume:\n",
        "    print(\"******Resume checkpoint******\")\n",
        "    accelerator.load_state(output_dir)\n",
        "    checkpoint = torch.load(os.path.join(output_dir, 'latest_checkpoint.pt'),\n",
        "                            map_location=\"cpu\")\n",
        "\n",
        "\n",
        " # Train\n",
        "total_batch_size = per_device_train_batch_size * accelerator.num_processes * gradient_accumulation_steps\n",
        "\n",
        "# Scheduler and math around the number of training steps.\n",
        "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / gradient_accumulation_steps)\n",
        "\n",
        "\n",
        "if max_train_steps is None:\n",
        "    max_train_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "\n",
        "# Afterwards we recalculate our number of training epochs\n",
        "num_train_epochs = math.ceil(max_train_steps / num_update_steps_per_epoch)\n",
        "\n",
        "if accelerator.is_main_process:\n",
        "    print(\"Number of training data: \", len(train_dataset))\n",
        "    print(\"total_batch_size: \", total_batch_size)\n",
        "    print(\"num_update_steps_per_epoch: \", num_update_steps_per_epoch)\n",
        "    print(\"num_train_epochs: \", num_train_epochs)\n",
        "\n",
        "# Only show the progress bar once on each machine.\n",
        "completed_steps = checkpoint['completed_steps'] + 1 if resume else 0\n",
        "starting_epoch = checkpoint['epoch'] if resume else 0\n",
        "progress_bar = tqdm(initial = completed_steps, total = max_train_steps, disable=not accelerator.is_local_main_process)\n",
        "\n",
        "print(f\"******STARTING AT EPOCH {starting_epoch} - STEP {completed_steps}******\")\n",
        "\n",
        "\n",
        "for epoch in range(starting_epoch, num_train_epochs):\n",
        "    if accelerator.is_main_process:\n",
        "        print(f\"\\nEpoch {epoch}: \")\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # compute num of losses\n",
        "        num_losses = batch[\"mask_time_indices\"].sum()\n",
        "        sub_attention_mask = batch.pop(\"sub_attention_mask\", None)\n",
        "        sub_attention_mask = (\n",
        "            sub_attention_mask if sub_attention_mask is not None else torch.ones_like(batch[\"mask_time_indices\"])\n",
        "        )\n",
        "        percent_masked = num_losses / sub_attention_mask.sum()\n",
        "\n",
        "        # forward\n",
        "        outputs = model(**batch)\n",
        "\n",
        "        # divide loss by gradient accumulation steps since gradients\n",
        "        # are accumulated for multiple backward passes in PyTorch\n",
        "        loss = outputs.loss / gradient_accumulation_steps\n",
        "        accelerator.backward(loss)\n",
        "\n",
        "        # make sure that `num_losses` is summed for distributed training\n",
        "        # and average gradients over losses of all devices\n",
        "        if accelerator.state.num_processes > 1:\n",
        "            num_losses = accelerator.gather(num_losses).sum()\n",
        "            gradient_multiplier = accelerator.state.num_processes / num_losses\n",
        "            multiply_grads(model.module.parameters(), gradient_multiplier)\n",
        "        else:\n",
        "            multiply_grads(model.parameters(), 1 / num_losses)\n",
        "\n",
        "        # update step\n",
        "        if (step + 1) % gradient_accumulation_steps == 0:\n",
        "\n",
        "            # compute grad norm for monitoring\n",
        "            scale = (\n",
        "                accelerator.scaler._scale.item()\n",
        "                if hasattr(accelerator, \"scaler\") and accelerator.scaler is not None\n",
        "                else 1\n",
        "            )\n",
        "            if accelerator.state.num_processes > 1:\n",
        "                grad_norm = get_grad_norm(model.module.parameters(), scale)\n",
        "            else:\n",
        "                grad_norm = get_grad_norm(model.parameters(), scale)\n",
        "\n",
        "            # update parameters\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if not accelerator.optimizer_step_was_skipped:\n",
        "                lr_scheduler.step()\n",
        "            elif accelerator.is_local_main_process:\n",
        "                progress_bar.write(\n",
        "                    f\"Gradients have overflown - skipping update step... Updating gradient scale to {scale}...\"\n",
        "                )\n",
        "\n",
        "            # update gumbel temperature\n",
        "            gumbel_temperature = max(\n",
        "                max_gumbel_temperature * gumbel_temperature_decay**completed_steps,\n",
        "                min_gumbel_temperature,\n",
        "            )\n",
        "            if hasattr(model, \"module\"):\n",
        "                model.module.set_gumbel_temperature(gumbel_temperature)\n",
        "            else:\n",
        "                model.set_gumbel_temperature(gumbel_temperature)\n",
        "\n",
        "            progress_bar.update(1)\n",
        "            completed_steps += 1\n",
        "\n",
        "        # Log all results\n",
        "        if (step + 1) % (gradient_accumulation_steps * logging_steps) == 0:\n",
        "            loss.detach()\n",
        "            outputs.contrastive_loss.detach()\n",
        "            outputs.diversity_loss.detach()\n",
        "            cosine_sim = torch.cosine_similarity(outputs.projected_states, outputs.projected_quantized_states, dim=-1)\n",
        "            cosine_sim = cosine_sim[batch[\"mask_time_indices\"].to(torch.bool)].mean()\n",
        "\n",
        "            if accelerator.state.num_processes > 1:\n",
        "                loss = accelerator.gather(loss).sum()\n",
        "                outputs.contrastive_loss = accelerator.gather(outputs.contrastive_loss).sum()\n",
        "                outputs.diversity_loss = accelerator.gather(outputs.diversity_loss).sum()\n",
        "                percent_masked = accelerator.gather(percent_masked).sum()\n",
        "                cosine_sim = accelerator.gather(cosine_sim).mean()\n",
        "\n",
        "            train_logs = {\n",
        "                \"step\": torch.tensor((step + 1) // gradient_accumulation_steps, dtype=torch.int32),\n",
        "                \"loss\": (loss * gradient_accumulation_steps) / num_losses,\n",
        "                \"contrast_loss\": outputs.contrastive_loss / num_losses,\n",
        "                \"div_loss\": outputs.diversity_loss / num_losses,\n",
        "                \"%_mask_idx\": percent_masked / accelerator.num_processes,\n",
        "                \"ppl\": outputs.codevector_perplexity,\n",
        "                \"lr\": torch.tensor(lr_scheduler.get_lr()),\n",
        "                \"temp\": torch.tensor(gumbel_temperature),\n",
        "                \"grad_norm\": torch.tensor(grad_norm),\n",
        "                \"cosine_sim\": cosine_sim * 100\n",
        "            }\n",
        "            log_str = \"\"\n",
        "            for k, v in train_logs.items():\n",
        "                log_str += \"| {}: {:.3e}\".format(k, v.item())\n",
        "\n",
        "            if accelerator.is_local_main_process:\n",
        "                progress_bar.write(log_str)\n",
        "                for k, v in train_logs.items():\n",
        "                    writer.add_scalar('TRAIN' + '/' + k, v, completed_steps)\n",
        "\n",
        "\n",
        "        # save model every `saving_steps` steps\n",
        "        if (step + 1) % (gradient_accumulation_steps * saving_steps) == 0:\n",
        "            if (push_to_hub and epoch < num_train_epochs - 1) or output_dir is not None:\n",
        "                accelerator.wait_for_everyone()\n",
        "                unwrapped_model = accelerator.unwrap_model(model)\n",
        "                unwrapped_model.save_pretrained(\n",
        "                        output_dir + f'/saved_model/epoch_{epoch}', is_main_process=accelerator.is_main_process, save_function=accelerator.save\n",
        "                    )\n",
        "                if accelerator.is_main_process:\n",
        "                    feature_extractor.save_pretrained(output_dir + f'/saved_model/epoch_{epoch}')\n",
        "                    print(\"****Saving checkpoint*****\")\n",
        "                    state_dict = {\n",
        "                        \"completed_steps\": completed_steps,\n",
        "                        \"epoch\": epoch\n",
        "                    }\n",
        "                    torch.save(state_dict, os.path.join(output_dir, \"latest_checkpoint.pt\"))\n",
        "                accelerator.save_state(output_dir)\n",
        "\n",
        "            if (push_to_hub and epoch < num_train_epochs - 1) and accelerator.is_main_process:\n",
        "                repo.push_to_hub(\n",
        "                    commit_message=f\"Training in progress step {completed_steps}\",\n",
        "                    blocking=False,\n",
        "                    auto_lfs_prune=True,\n",
        "                )\n",
        "\n",
        "        # if completed steps > `max_train_steps` stop\n",
        "        if completed_steps >= max_train_steps:\n",
        "            break\n",
        "\n",
        "    print(\"******END OF EPOCH******\")\n",
        "    # Validate!\n",
        "    model.eval()\n",
        "\n",
        "    # init logs\n",
        "    val_logs = {\n",
        "        \"val_loss\": 0,\n",
        "        \"val_contrastive_loss\": 0,\n",
        "        \"val_diversity_loss\": 0,\n",
        "        \"val_num_losses\": 0,\n",
        "    }\n",
        "    for step, batch in enumerate(eval_dataloader):\n",
        "        with torch.no_grad():\n",
        "            batch.pop(\"sub_attention_mask\", None)\n",
        "            outputs = model(**batch)\n",
        "\n",
        "        val_logs[\"val_loss\"] += outputs.loss\n",
        "        val_logs[\"val_contrastive_loss\"] += outputs.contrastive_loss\n",
        "        val_logs[\"val_diversity_loss\"] += outputs.diversity_loss\n",
        "        val_logs[\"val_num_losses\"] += batch[\"mask_time_indices\"].sum()\n",
        "\n",
        "    # sum over devices in multi-processing\n",
        "    if accelerator.num_processes > 1:\n",
        "        val_logs = {k: accelerator.gather(v).sum() for k, v in val_logs.items()}\n",
        "\n",
        "    val_logs = {k: v / val_logs[\"val_num_losses\"] for k, v in val_logs.items()}\n",
        "\n",
        "    log_str = \"\"\n",
        "    for k, v in val_logs.items():\n",
        "        log_str += \"| {}: {:.3e}\".format(k, v.item())\n",
        "\n",
        "    if accelerator.is_local_main_process:\n",
        "        progress_bar.write(log_str)\n",
        "        for k, v in val_logs.items():\n",
        "            writer.add_scalar('VALIDATION' + '/' + k, v, epoch)\n",
        "\n",
        "    if output_dir is not None:\n",
        "        accelerator.wait_for_everyone()\n",
        "        unwrapped_model = accelerator.unwrap_model(model)\n",
        "        unwrapped_model.save_pretrained(\n",
        "                output_dir + f'/saved_model/epoch_{epoch}', is_main_process=accelerator.is_main_process, save_function=accelerator.save\n",
        "            )\n",
        "        if accelerator.is_main_process:\n",
        "            feature_extractor.save_pretrained(output_dir + f'/saved_model/epoch_{epoch}')\n",
        "            print(\"****Saving checkpoint*****\")\n",
        "            state_dict = {\n",
        "                \"completed_steps\": completed_steps,\n",
        "                \"epoch\": epoch\n",
        "            }\n",
        "            torch.save(state_dict, os.path.join(output_dir, \"latest_checkpoint.pt\"))\n",
        "\n",
        "        accelerator.save_state(output_dir)\n",
        "        if accelerator.is_main_process:\n",
        "            if push_to_hub:\n",
        "                repo.push_to_hub(commit_message=\"End of training\", auto_lfs_prune=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
