{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data for Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2022 Herman Kamper, MIT License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████| 1305990/1305990 [00:01<00:00, 766610.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 22035/22035 [00:00<00:00, 491290.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 100281/100281 [00:00<00:00, 608550.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"data/language_model_data/data/\")\n",
    "langs = [\"af\", \"xh\", \"zu\"]\n",
    "\n",
    "original_data = {}\n",
    "for lang in langs:\n",
    "    line_count_ignored = 0\n",
    "    lang_fn = data_dir/f\"cleaned_wikipedia.{lang}.txt\"\n",
    "    with open(str(lang_fn)) as f:\n",
    "        lines = f.readlines()\n",
    "    new_lines = []\n",
    "    \n",
    "    for line in tqdm(lines):\n",
    "        if (len(line) > 20):\n",
    "            new_lines.append(line)\n",
    "        else:\n",
    "            line_count_ignored += 1\n",
    "    original_data[lang] = new_lines\n",
    "    print(line_count_ignored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 10000\n",
    "n_val = 5000\n",
    "n_test = 1000\n",
    "\n",
    "train_data = {}\n",
    "val_data = {}\n",
    "test_data = {}\n",
    "\n",
    "for lang in original_data:\n",
    "    train_data[lang] = original_data[lang][:n_train]\n",
    "    val_data[lang] = original_data[lang][n_train:n_train + n_val]\n",
    "    test_data[lang] = original_data[lang][n_train + n_val:n_train + n_val + n_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: af\n",
      "Writing: data/language_model_data/train.af.txt\n",
      "\n",
      "Language: xh\n",
      "Writing: data/language_model_data/train.xh.txt\n",
      "\n",
      "Language: zu\n",
      "Writing: data/language_model_data/train.zu.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write data\n",
    "output_dir = Path(\"data/language_model_data/\")\n",
    "for lang in train_data:\n",
    "    print(f\"Language: {lang}\")\n",
    "    lang_fn = output_dir/f\"train.{lang}.txt\"\n",
    "    print(f\"Writing: {lang_fn}\")\n",
    "    with open(lang_fn, \"w\") as f:\n",
    "        for line in train_data[lang]:\n",
    "            f.write(line)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize validation and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import remove_special_characters\n",
    "\n",
    "def preprocess_line(line):\n",
    "#     line = line.lower()\n",
    "\n",
    "#     # Remove accents\n",
    "#     line = re.sub(u\"[àáâãäå]\", \"a\", line)\n",
    "#     line = re.sub(u\"[èéêë]\", \"e\", line)\n",
    "#     line = re.sub(u\"[ìíîï]\", \"i\", line)\n",
    "#     line = re.sub(u\"[òóôõö]\", \"o\", line)\n",
    "#     line = re.sub(u\"[ùúûü]\", \"u\", line)\n",
    "#     line = re.sub(u\"[ýÿ]\", \"y\", line)\n",
    "#     line = re.sub(u\"[ß]\", \"ss\", line)\n",
    "#     line = re.sub(u\"[ñ]\", \"n\", line)\n",
    "\n",
    "#     # Map all digits to 0\n",
    "#     line = re.sub(r\"[0-9]\", \"0\", line)\n",
    "#     line = re.sub(r\"([0]+)\", \" \\g<1> \", line)  # add space before and after 0\n",
    "    \n",
    "#     # Add space before and after . or ,\n",
    "#     line = re.sub(r\"([\\.\\,])\", \" \\g<1> \", line)\n",
    "\n",
    "#     # Remove all redundant characteres\n",
    "# #     line = re.sub(r\"[^a-z0\\.\\ \\,]\", \"\", line)\n",
    "# #     line = re.sub(r\"[^a-z\\ ]\", \"\", line)\n",
    "#     line = re.sub(r\"[^a-z0\\ ]\", \"\", line)\n",
    "    \n",
    "#     # Eliminate duplicate whitespaces\n",
    "#     line = re.sub(r\"\\s+\", \" \", line)\n",
    "    return remove_special_characters(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: af\n",
      "No. lines: 14901\n",
      "No. unique lines: 14776\n",
      "No. val lines: 5000\n",
      "\n",
      "Language: xh\n",
      "No. lines: 902\n",
      "No. unique lines: 901\n",
      "No. val lines: 901\n",
      "\n",
      "Language: zu\n",
      "No. lines: 7310\n",
      "No. unique lines: 3010\n",
      "No. val lines: 3010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "val_data_normalized = {}\n",
    "for lang in val_data:\n",
    "# for lang in [\"zu\", ]:\n",
    "    val_data_normalized[lang] = []\n",
    "    for line in val_data[lang]:\n",
    "        split_lines = re.findall(r\".*?[.?!][.?!\\s]+\", line)\n",
    "#         print(split_lines)\n",
    "#         print(line)\n",
    "#         assert False\n",
    "        val_data_normalized[lang] += [preprocess_line(i) for i in split_lines]\n",
    "    print(f\"Language: {lang}\")\n",
    "    print(f\"No. lines: {len(val_data_normalized[lang])}\")\n",
    "    val_data_normalized[lang] = list(set(val_data_normalized[lang]))\n",
    "    print(f\"No. unique lines: {len(val_data_normalized[lang])}\")\n",
    "    val_data_normalized[lang] = val_data_normalized[lang][:n_val]\n",
    "    print(f\"No. val lines: {len(val_data_normalized[lang])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: af\n",
      "Writing: data/language_model_data/val.af.txt\n",
      "\n",
      "Language: xh\n",
      "Writing: data/language_model_data/val.xh.txt\n",
      "\n",
      "Language: zu\n",
      "Writing: data/language_model_data/val.zu.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Write data\n",
    "for lang in val_data:\n",
    "    print(f\"Language: {lang}\")\n",
    "    lang_fn = output_dir/f\"val.{lang}.txt\"\n",
    "    print(f\"Writing: {lang_fn}\")\n",
    "    with open(lang_fn, \"w\") as f:\n",
    "        for line in val_data_normalized[lang]:\n",
    "            f.write(line + \"\\n\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: af\n",
      "No. lines: 2562\n",
      "No. unique lines: 2560\n",
      "No. test lines: 1000\n",
      "\n",
      "Language: xh\n",
      "No. lines: 0\n",
      "No. unique lines: 0\n",
      "No. test lines: 0\n",
      "\n",
      "Language: zu\n",
      "No. lines: 1414\n",
      "No. unique lines: 501\n",
      "No. test lines: 501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_data_normalized = []\n",
    "test_labels = []\n",
    "for lang in test_data:\n",
    "    print(f\"Language: {lang}\")\n",
    "    test_lines_lang = []\n",
    "    for line in test_data[lang]:\n",
    "        split_lines = re.findall(r\".*?[.?!][.?!\\s]+\", line)\n",
    "        test_lines_lang += [preprocess_line(i) for i in split_lines]\n",
    "    print(f\"No. lines: {len(test_lines_lang)}\")\n",
    "    test_lines_lang = list(set(test_lines_lang))\n",
    "    print(f\"No. unique lines: {len(test_lines_lang)}\")\n",
    "    test_lines_lang = test_lines_lang[:n_test]\n",
    "    print(f\"No. test lines: {len(test_lines_lang)}\")\n",
    "    test_data_normalized += test_lines_lang\n",
    "    test_labels += [lang]*n_test\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. test items:  1501\n",
      "Total no. test labels: 1501\n"
     ]
    }
   ],
   "source": [
    "# Shuffle test data\n",
    "import random\n",
    "random.seed(1)\n",
    "\n",
    "temp = list(zip(test_data_normalized, test_labels))\n",
    "random.shuffle(temp)\n",
    "res1, res2 = zip(*temp)\n",
    "test_data_normalized, test_labels = list(res1), list(res2)\n",
    "\n",
    "print(f\"Total no. test items:  {len(test_data_normalized)}\")\n",
    "print(f\"Total no. test labels: {len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "af selfs al glo baie dat die beginsels waarop die dvoraksleutelbord gebaseer is beter is as die ouer qwerty het pogings om wêreldwyd na die dvorakuitleg oor te skakel baie weerstand ondervind \n",
      "xh iroox yidolobha elikwisifundazwe se mudug esomaliya\n",
      "\n",
      "af kommissies bestaande uit lede van die sweedse akademie vir wetenskap (vir ekonomie natuur en skeikunde) en die koninklike karolingiese instituut vir geneeskunde (vir geneeskunde fisiologie) stuur in die europese herfs tussen 2 000 en 3000 vertroulike briewe uit waarin die name van moontlike kandidate aangevra word \n",
      "\n",
      "xh loluhlelo lusebenzisa amakhodi ukuchaza izifunda izifundazwe kanye namazwe\n",
      "\n",
      "af slegs 10 van bophuthatswana se totale grondoppervlakte was bewerkbaar en meeste daarvan was met veldstruike bedek\n",
      "\n",
      "xh leli dolobha layisiqongo sesifunda se meru north esaqedwa ngonyaka wezi2009\n",
      "\n",
      "af baie huldig die teorie dat waterstof sulke brandstowwe in die toekoms mag vervang \n",
      "af turbulensie in die atmosfeer veroorsaak ook vonkeling (ŉ gedurige verandering in helderheid) asook n effense verandering in posisie \n",
      "\n",
      "xh isablale yisifunda esingaphansi kwesifundazwe se lower shabelle esomaliya\n",
      "\n",
      "af n formule een grand prix vind oor die tydperk van n naweek plaas en begin met vrye oefeninge op die vrydag \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"{test_labels[i]} {test_data_normalized[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing: data/language_model_data/test.lid.txt\n"
     ]
    }
   ],
   "source": [
    "# Write data\n",
    "fn = output_dir/f\"test.lid.txt\"\n",
    "print(f\"Writing: {fn}\")\n",
    "with open(fn, \"w\") as f:\n",
    "    for lang, line in zip(test_labels, test_data_normalized):\n",
    "        f.write(f\"{lang} {line}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
